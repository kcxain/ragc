{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: http_proxy=http://127.0.0.1:10890\n",
      "env: https_proxy=http://127.0.0.1:10890\n",
      "env: no_proxy=127.0.0.1,localhost\n",
      "env: HTTP_PROXY=http://127.0.0.1:10890\n",
      "env: HTTPS_PROXY=http://127.0.0.1:10890\n",
      "env: NO_PROXY=127.0.0.1,localhost\n",
      "\u001b[32m[√] 已开启代理\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env http_proxy=http://127.0.0.1:10890\n",
    "%env https_proxy=http://127.0.0.1:10890\n",
    "%env no_proxy=127.0.0.1,localhost\n",
    "%env HTTP_PROXY=http://127.0.0.1:10890\n",
    "%env HTTPS_PROXY=http://127.0.0.1:10890\n",
    "%env NO_PROXY=127.0.0.1,localhost\n",
    "!echo -e \"\\033[32m[√] 已开启代理\\033[0m\"\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from assistant import check_local\n",
    "from search import search_github\n",
    "\n",
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import faiss\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from search import search_github\n",
    "from download import load_readme\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "embeddings = OpenAIEmbeddings()\n",
    "def download_readme_to_db(keywords: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Search github repos with a list of detailed keywords, and save the readme of them into a vector database. Return the path of db\n",
    "    \"\"\"\n",
    "    keywords = [keyword.lower().strip() for keyword in keywords][:1]\n",
    "    keywords = [\"gaussian splatting\"]\n",
    "    db_path = check_local(keywords)\n",
    "    # vector_store = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    if not db_path:\n",
    "        repos = search_github(keywords, 1)\n",
    "        vector_store = FAISS(\n",
    "                        embedding_function=embeddings,\n",
    "                        index=faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\"))),\n",
    "                        docstore=InMemoryDocstore(),\n",
    "                        index_to_docstore_id={},\n",
    "                    )\n",
    "        load_readme(repos, vector_store)\n",
    "        db_file_name = '-'.join(keywords).lower()\n",
    "        db_path = f'./db/{db_file_name}'\n",
    "        vector_store.save_local(db_path)\n",
    "    return db_path\n",
    "\n",
    "def search_db(db_path: str, text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search with the text from a vector db loaded from db_path, and return the descriptions and readme of top related repos\n",
    "    \"\"\"\n",
    "    vector_store = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)\n",
    "    bm25_retriever = BM25Retriever.from_documents(vector_store.docstore._dict.values())\n",
    "    faiss_retriever = vector_store.as_retriever()\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[bm25_retriever, faiss_retriever], weights=[0.8, 0.2]\n",
    "    )\n",
    "    similar_repos = ensemble_retriever.invoke(text)\n",
    "    return [{\"repo_name\": repo.metadata[\"repo_name\"], \"repo_readme\": repo.page_content} for repo in similar_repos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your requirements, here's a GitHub repository related to \"3D Gaussian Splatting for Real-Time Radiance Field Rendering\" that seems to match your criteria, although it's worth noting that it primarily uses PyTorch and OpenGL, which involves GPU usage. \n",
      "\n",
      "**Repository Name:** [ue-abyar/Persian-Gaussian-Splatting](https://github.com/ue-abyar/Persian-Gaussian-Splatting)\n",
      "\n",
      "The repository contains:\n",
      "\n",
      "- An OpenGL-based real-time viewer to render trained models.\n",
      "- A PyTorch-based optimizer for 3D Gaussian model production.\n",
      "- Dependency on a CUDA-ready GPU for the real-time viewer.\n",
      "\n",
      "While the optimizer utilizes GPU (PyTorch), the real-time viewer is OpenGL-based. If you want something completely C/C++ kernel-based that's strictly CPU-only, you might need to adjust the current code or search more specifically due to the GPU dependencies described herein. Adjustments can involve removing CUDA elements if a CPU-only implementation is essential, although this might heavily affect performance.\n",
      "\n",
      "Please review the details in this repo to ensure it aligns closely enough with your intent or see if parts of it can be adapted to your needs!\n"
     ]
    }
   ],
   "source": [
    "from swarm import Swarm, Agent\n",
    "\n",
    "client = Swarm()\n",
    "\n",
    "def transfer_to_writer():\n",
    "    return writer\n",
    "\n",
    "def transfer_to_tool_user():\n",
    "    return tool_user\n",
    "\n",
    "\n",
    "def transfer_to_reviewer():\n",
    "    return reviewer\n",
    "\n",
    "tool_user = Agent(\n",
    "    name=\"Tool_user A\",\n",
    "    instructions=\"\"\"Tool_user. You need to plan how to use the tools you have and find the GitHub repository that best meets user's requirements.. \n",
    "    Capable of understanding a detailed algorithm description provided by the user, interpreting the algorithm code needed, and determining the requirements for the code (such as the programming language, whether it can run on CPU/GPU, etc.). \n",
    "    You will find the GitHub repository that best meets these requirements. \n",
    "    1. You should use download_readme_to_db to get the path of db before search the database.\n",
    "    2. Use the text generated by Writer to seach the database.\n",
    "    \"\"\",\n",
    "    functions=[transfer_to_writer, transfer_to_reviewer, download_readme_to_db, search_db],\n",
    ")\n",
    "\n",
    "writer = Agent(\n",
    "    name=\"Writer\",\n",
    "    instructions=\"\"\"Writer. Your task is to generate a README file for a project that aligns as closely as possible with the user's specified algorithm requirements. \n",
    "    The README must highlight and prioritize the user's specific needs, such as programming language, hardware compatibility (CPU/GPU), performance optimization, and any other explicit details provided in the algorithm description.\n",
    "    \"\"\",\n",
    "    functions=[transfer_to_tool_user],\n",
    ")\n",
    "\n",
    "reviewer = Agent(\n",
    "    name=\"Reviewer\",\n",
    "    instructions=\"\"\"Reviewer. Review the top related repos provided by Tool_user after use search_db and select the one that best matches the user's algorithm requirements. \n",
    "    After returning the repository name, output TERMINATE to signal the completion of the task.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "response = client.run(\n",
    "    agent=tool_user,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Give me the most related github repo whose code is written with C kernel and can be run on the CPU of this title and abstract: 3D Gaussian Splatting for Real-Time Radiance Field Rendering Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos. However, achieving high visual quality still requires neural networks that are costly to train and render, while recent faster methods inevitably trade off speed for quality. For unbounded and complete scenes (rather than isolated objects) and 1080p resolution rendering, no current method can achieve real-time display rates. We introduce three key elements that allow us to achieve state-of-the-art visual quality while maintaining competitive training times and importantly allow high-quality real-time (≥ 30 fps) novel-view synthesis at 1080p resolution. First, starting from sparse points produced during camera calibration, we represent the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space; Second, we perform interleaved optimization/density control of the 3D Gaussians, notably optimizing anisotropic covariance to achieve an accurate representation of the scene; Third, we develop a fast visibility-aware rendering algorithm that supports anisotropic splatting and both accelerates training and allows realtime rendering. We demonstrate state-of-the-art visual quality and real-time rendering on several established datasets.\"}],\n",
    ")\n",
    "\n",
    "print(response.messages[-1][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
